{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4163a40-b900-4775-890f-5e57e0931c6a",
   "metadata": {},
   "source": [
    "## Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6941ee89-e5e7-40cc-a39b-a4b2b8621ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254df4ff-7225-4730-8bd8-5fb2929cd663",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaa7f82-e0d4-4149-8c8b-615eabc029f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read only the first two columns\n",
    "#df = pd.read_csv(\"Waste_3_6.csv\", usecols=[0, 1]) ### two months data\n",
    "\n",
    "df = pd.read_csv(\"Waste_3_6_July_Nov.csv\", usecols=[0, 1])  ### new data set\n",
    "\n",
    "# Rename columns\n",
    "df.columns = [\"Datetime\", \"Flow[cfs]\"]\n",
    "\n",
    "# Convert to datetime (auto-detects all formats)\n",
    "df[\"Datetime\"] = pd.to_datetime(df[\"Datetime\"], errors=\"coerce\")\n",
    "\n",
    "# Convert flow values to numeric\n",
    "df[\"Flow[cfs]\"] = pd.to_numeric(df[\"Flow[cfs]\"], errors=\"coerce\")\n",
    "\n",
    "# Drop invalid rows and set datetime index\n",
    "df = df.dropna(subset=[\"Datetime\"]).set_index(\"Datetime\")\n",
    "\n",
    "# Count how many have missing flow values\n",
    "missing_points = df[\"Flow[cfs]\"].isna().sum()\n",
    "\n",
    "# Display first few rows\n",
    "print(df.head())\n",
    "print(\"Missing point\",missing_points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66af252c-5942-432a-8ad5-d8c4e82f14df",
   "metadata": {},
   "source": [
    "### Resample into 10 min flow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473e9a97-8c5a-44ed-95da-8cc045dfe524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample to a strict 10-minute grid and compute the mean per bin\n",
    "flow_10min = df.resample(\"10min\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4485c6dd-ebb4-473a-8a13-a957d76f135b",
   "metadata": {},
   "source": [
    "### detecting and handliing outliers if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e959f4ff-2c63-4c3a-9f64-1b487c8fd9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute quartiles\n",
    "Q1 = flow_10min[\"Flow[cfs]\"].quantile(0.25)\n",
    "Q3 = flow_10min[\"Flow[cfs]\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Bounds\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Identify outliers\n",
    "outliers = flow_10min[\n",
    "    (flow_10min[\"Flow[cfs]\"] < lower_bound) | \n",
    "    (flow_10min[\"Flow[cfs]\"] > upper_bound)\n",
    "]\n",
    "\n",
    "print(f\"Total outliers detected: {len(outliers)}\")\n",
    "print(f\"Lower bound: {lower_bound:.3f}, Upper bound: {upper_bound:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3450b169-881a-4d0d-bbbb-511db906788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_10min.loc[\n",
    "    (flow_10min[\"Flow[cfs]\"] < lower_bound) | \n",
    "    (flow_10min[\"Flow[cfs]\"] > upper_bound), \n",
    "    \"Flow[cfs]\"\n",
    "] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68a2dc4-19de-485e-bce5-b21bbfedd544",
   "metadata": {},
   "source": [
    "### Interpolate missing and outlier gaps (time-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49628b0e-3b21-4c41-a401-71c77c80a5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill gaps smoothly if there are any using time-based interpolation\n",
    "flow_10min = flow_10min.interpolate(method=\"time\")\n",
    "\n",
    "# Display first few rows\n",
    "print(flow_10min.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89142a1f-47dd-4ab4-8d58-4bd2700649e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Since I don't have access to your specific flow_10min DataFrame,\n",
    "# I'll assume it contains time series data with a datetime index\n",
    "# and one or more columns of flow measurements\n",
    "\n",
    "# If your DataFrame is already defined, you can skip this part\n",
    "# This is just an example of what the DataFrame might look like\n",
    "# flow_10min = pd.DataFrame(your_data_here)\n",
    "\n",
    "# Basic plotting of the entire DataFrame\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# If flow_10min has multiple columns, this will plot all of them\n",
    "flow_10min.plot(ax=ax)\n",
    "\n",
    "# If you want to plot just one specific column, uncomment and modify this line:\n",
    "# flow_10min['your_column_name'].plot(ax=ax)\n",
    "\n",
    "# Enhance the plot with labels and title\n",
    "plt.title('Flow Data (10-minute intervals)', fontsize=14)\n",
    "plt.xlabel('Time', fontsize=12)\n",
    "plt.ylabel('Flow Rate', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add a legend if there are multiple columns\n",
    "plt.legend(loc='best')\n",
    "\n",
    "# Rotate x-axis labels if they're overlapping\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Adjust layout to prevent cut-off labels\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c787c688-cb87-4831-9c6b-2662325219b6",
   "metadata": {},
   "source": [
    "# ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82a8b35-1e8d-4ec8-8d9d-69efa4b95b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, random\n",
    "from math import sqrt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996ffec4-e3f3-4859-a3fa-b9a54e129131",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfb7f08-bc28-4cb1-beb0-cb505306a0c6",
   "metadata": {},
   "source": [
    "### Time-ordered split 70:15:15 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ceab54-53c7-495a-b0c9-34dfead0fe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=len(flow_10min)\n",
    "n_train=int(0.70*N); n_val=int(0.15*N); n_test=N-n_train-n_val\n",
    "train_df=flow_10min.iloc[:n_train].copy()\n",
    "val_df  =flow_10min.iloc[n_train:n_train+n_val].copy()\n",
    "test_df =flow_10min.iloc[n_train+n_val:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baa29f4-4805-46ef-a9cf-ec47768ac749",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db58392-cee1-45bb-b6d8-3fc0ea516c6a",
   "metadata": {},
   "source": [
    " ### Scale on TRAIN only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac36eef-f906-4a77-8fe2-5c82b37b16a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler()\n",
    "scaler.fit(train_df[['Flow[cfs]']].values)\n",
    "train_scaled=scaler.transform(train_df[['Flow[cfs]']].values)\n",
    "val_scaled  =scaler.transform(val_df[['Flow[cfs]']].values)\n",
    "test_scaled =scaler.transform(test_df[['Flow[cfs]']].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215608d2-28a2-42cd-84c0-6f228dcafe76",
   "metadata": {},
   "source": [
    "### Windowing (Sliding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89914dca-ef12-43a4-b31d-71c566604fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "H=36   # 6 hours ahead (10-min steps)\n",
    "L=144  # 24 hours lookback (10-min steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f2e193-85f2-4d1a-9000-d12f9f171697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_windows(series_2d, lookback=L, horizon=H):\n",
    "    x_list, y_list=[], []\n",
    "    T=len(series_2d)\n",
    "    end = T - lookback - horizon + 1\n",
    "    for i in range(end):\n",
    "        x = series_2d[i:i+lookback]                      # [L,1]\n",
    "        y = series_2d[i+lookback:i+lookback+horizon,0]   # [H]\n",
    "        x_list.append(x); y_list.append(y)\n",
    "    if not x_list:\n",
    "        return np.empty((0,lookback,1)), np.empty((0,horizon))\n",
    "    return np.stack(x_list), np.stack(y_list)\n",
    "\n",
    "X_train,y_train=make_windows(train_scaled,L,H)\n",
    "X_val,y_val    =make_windows(val_scaled,L,H)\n",
    "X_test,y_test  =make_windows(test_scaled,L,H)\n",
    "\n",
    "class SeqDS(Dataset):\n",
    "    def __init__(self,X,y): self.X=torch.from_numpy(X).float(); self.y=torch.from_numpy(y).float()\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self,i): return self.X[i], self.y[i]\n",
    "\n",
    "bs=128\n",
    "train_loader=DataLoader(SeqDS(X_train,y_train),batch_size=bs,shuffle=True)\n",
    "val_loader  =DataLoader(SeqDS(X_val,y_val),batch_size=bs,shuffle=False)\n",
    "test_loader =DataLoader(SeqDS(X_test,y_test),batch_size=bs,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da61a851-8621-4827-a683-74e702ebb09f",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30328350-efd2-4b7c-bf77-bb94f326740c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMForecaster(nn.Module):\n",
    "    def __init__(self,input_dim=1,hidden=128,layers=2,dropout=0.2,horizon=H):\n",
    "        super().__init__()\n",
    "        self.lstm=nn.LSTM(input_dim,hidden,num_layers=layers,\n",
    "                          dropout=dropout if layers>1 else 0.0,batch_first=True)\n",
    "        self.head=nn.Sequential(nn.Linear(hidden,64), nn.ReLU(), nn.Linear(64,horizon))\n",
    "    def forward(self,x):\n",
    "        out,_=self.lstm(x)           # [B,L,hidden]\n",
    "        last=out[:,-1,:]             # [B,hidden]\n",
    "        return self.head(last)       # [B,H]\n",
    "\n",
    "model=LSTMForecaster(horizon=H).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70eb4686-6444-4676-8f61-2787db99337a",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a920659-c94c-4629-9fd7-9f4c52d0d85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "crit=nn.MSELoss()\n",
    "opt=torch.optim.Adam(model.parameters(),lr=1e-3)\n",
    "sched=torch.optim.lr_scheduler.ReduceLROnPlateau(opt,mode='min',patience=4,factor=0.5,verbose=True)\n",
    "\n",
    "best=np.inf; patience=8; pat=0; best_state=None\n",
    "\n",
    "def eval_loader(dl):\n",
    "    model.eval(); losses=[]\n",
    "    with torch.no_grad():\n",
    "        for xb,yb in dl:\n",
    "            xb,yb=xb.to(device), yb.to(device)\n",
    "            losses.append(crit(model(xb), yb).item())\n",
    "    return float(np.mean(losses))\n",
    "\n",
    "for ep in range(1, 60+1):\n",
    "    model.train(); tr=[]\n",
    "    for xb,yb in train_loader:\n",
    "        xb,yb=xb.to(device), yb.to(device)\n",
    "        opt.zero_grad(); yhat=model(xb); loss=crit(yhat,yb)\n",
    "        loss.backward(); torch.nn.utils.clip_grad_norm_(model.parameters(),1.0)\n",
    "        opt.step(); tr.append(loss.item())\n",
    "    val=eval_loader(val_loader); sched.step(val)\n",
    "    print(f\"Epoch {ep:03d} | train {np.mean(tr):.6f} | val {val:.6f}\")\n",
    "    if val < best - 1e-6:\n",
    "        best=val; best_state={k:v.cpu().clone() for k,v in model.state_dict().items()}; pat=0\n",
    "    else:\n",
    "        pat+=1\n",
    "        if pat>=patience:\n",
    "            print(\"Early stopping\"); break\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state); model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281ba3f2-f26a-474d-b727-d1e7e1b9f5f1",
   "metadata": {},
   "source": [
    "### Evaluation in cfs (per step + overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2cd32e-1b15-4f5f-ab7b-f31f990801a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_scale(Y_scaled):\n",
    "    tmp=np.zeros((Y_scaled.size,1)); tmp[:,0]=Y_scaled.reshape(-1)\n",
    "    inv=scaler.inverse_transform(tmp)[:,0]\n",
    "    return inv.reshape(Y_scaled.shape)\n",
    "\n",
    "def compute_metrics(y_true,y_pred):\n",
    "    mae = np.mean(np.abs(y_true-y_pred),axis=0)\n",
    "    rmse= np.sqrt(np.mean((y_true-y_pred)**2,axis=0))\n",
    "    overall_mae=float(np.mean(np.abs(y_true-y_pred)))\n",
    "    overall_rmse=float(np.sqrt(np.mean((y_true-y_pred)**2)))\n",
    "    return mae, rmse, overall_mae, overall_rmse\n",
    "\n",
    "model.eval(); preds=[]; truth=[]\n",
    "with torch.no_grad():\n",
    "    for xb,yb in test_loader:\n",
    "        yhat=model(xb.to(device)).cpu().numpy()\n",
    "        preds.append(yhat); truth.append(yb.numpy())\n",
    "y_pred_s=np.vstack(preds); y_true_s=np.vstack(truth)\n",
    "y_pred = inverse_scale(y_pred_s); y_true = inverse_scale(y_true_s)\n",
    "\n",
    "mae_h, rmse_h, mae_all, rmse_all = compute_metrics(y_true, y_pred)\n",
    "print(\"\\n=== Test metrics (cfs) ===\")\n",
    "for i in range(H):\n",
    "    print(f\"+{(i+1)*10:>3} min: MAE={mae_h[i]:.4f} | RMSE={rmse_h[i]:.4f}\")\n",
    "print(f\"Overall MAE:  {mae_all:.4f} cfs\")\n",
    "print(f\"Overall RMSE: {rmse_all:.4f} cfs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd56230-6636-42cd-b447-391c391255ea",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bc0ac9-cb21-4e35-8534-5a91c3394655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "\n",
    "def plot_test_sample(sample_idx=0):\n",
    "    \"\"\"\n",
    "    Plots one test window:\n",
    "      - input history (last 24h = L points)\n",
    "      - predicted next 6h (H points) vs observed next 6h\n",
    "    \"\"\"\n",
    "\n",
    "    # --- pull raw series and timestamps from the test split ---\n",
    "    series = test_df['Flow[cfs]']                      # raw (cfs), DatetimeIndex at 10-min\n",
    "    idx = series.index\n",
    "\n",
    "    # total number of test windows created by make_windows\n",
    "    N_windows = len(series) - L - H + 1\n",
    "    if N_windows <= 0:\n",
    "        raise ValueError(\"Not enough test data to form a window. Check L/H and split sizes.\")\n",
    "    sample = max(0, min(sample_idx, N_windows-1))\n",
    "\n",
    "    # time ranges for input and targets in the TEST split\n",
    "    hist_slice = slice(sample, sample + L)                 # [i .. i+L-1]\n",
    "    fut_slice  = slice(sample + L, sample + L + H)         # [i+L .. i+L+H-1]\n",
    "\n",
    "    # inverse-scaled predictions for the whole test set were computed as y_pred (np.array [N,H])\n",
    "    # We need the matching row for this sample:\n",
    "    y_pred_sample = y_pred[sample]                         # shape [H]\n",
    "    y_true_sample = y_true[sample]                         # shape [H]\n",
    "\n",
    "    # gather timestamps\n",
    "    hist_times = idx[hist_slice]\n",
    "    fut_times  = idx[fut_slice]                            # these are t+10min..t+6h\n",
    "\n",
    "    # values for the history (already raw cfs)\n",
    "    hist_vals  = series.iloc[hist_slice].values\n",
    "\n",
    "    # --- plot ---\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    # history\n",
    "    plt.plot(hist_times, hist_vals, label=\"History (last 24h)\", linewidth=1.5)\n",
    "    # future observed vs predicted\n",
    "    plt.plot(fut_times, y_true_sample, label=\"Observed (next 6h)\", linewidth=2)\n",
    "    plt.plot(fut_times, y_pred_sample, label=\"Predicted (next 6h)\", linestyle=\"--\", linewidth=2)\n",
    "\n",
    "    # visual cue at forecast boundary\n",
    "    t_cut = hist_times[-1]\n",
    "    plt.axvline(t_cut, linestyle=\":\", linewidth=1)\n",
    "    plt.text(t_cut, max(np.nanmax(hist_vals), np.nanmax(y_true_sample))*1.01,\n",
    "             \" forecast start\", rotation=90, va=\"bottom\", ha=\"left\")\n",
    "\n",
    "    plt.title(f\"Test sample #{sample} — 24h history + 6h forecast\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Flow (cfs)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example: first sample\n",
    "plot_test_sample(0)\n",
    "\n",
    "# Or pick a middle/random sample\n",
    "# plot_test_sample(100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a3b80b-7341-4bbf-8a67-7636ab8235e1",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c92a2e6-642a-45e7-8a0b-ea37b244f3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"lstm_flow_10min_h36_L144.pt\")\n",
    "joblib.dump(scaler,\"scaler_minmax_flow.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eab3236-3a3a-4eb7-9983-f296a584959f",
   "metadata": {},
   "source": [
    "### Inference helper (needs last 24h=144 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7888a6e3-2e06-4e98-a366-c359e2b4605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_next_6hrs(flow_last_24h_series):\n",
    "    assert len(flow_last_24h_series)==L\n",
    "    x=scaler.transform(flow_last_24h_series.values.reshape(-1,1))\n",
    "    x_t=torch.from_numpy(x).float().unsqueeze(0).to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        yhat_s=model(x_t).cpu().numpy()  # [1,36]\n",
    "    return inverse_scale(yhat_s)[0]      # 36 forecasts in cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454ab217-63cf-499d-9d7b-5750763066a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4e9d8ae-24d5-4adc-962f-2cc59343b4a1",
   "metadata": {},
   "source": [
    "### Imports & config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793726a6-0c02-4f02-a22e-a8c45e0baab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== 0) Imports & config =====================\n",
    "import numpy as np, pandas as pd, random, math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import amp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e6e66d-d3b1-4bee-9d49-fd71251e9dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "H, L = 6, 144   # 6h horizon, 24h lookback (10-min steps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d30fd7-1396-4073-9e27-2e119fa9ad32",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5647d367-b67d-4bd7-a1f5-282944b8b299",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = flow_10min.copy().sort_index().asfreq('10min')\n",
    "assert 'Flow[cfs]' in df.columns, \"Expected a column named 'Flow[cfs]'\"\n",
    "df['Flow[cfs]'] = df['Flow[cfs]'].interpolate(limit_direction='both')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcf76f8-128c-4fc4-8192-c99c58c0d4e4",
   "metadata": {},
   "source": [
    "### 70/15/15 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6ba2f0-8158-4899-a1fc-43dda2a76a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=len(df); n_tr=int(0.70*N); n_va=int(0.15*N)\n",
    "train_df=df.iloc[:n_tr].copy()\n",
    "val_df  =df.iloc[n_tr:n_tr+n_va].copy()\n",
    "test_df =df.iloc[n_tr+n_va:].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f75b9f-f43d-4948-8983-1ae7fed96ccf",
   "metadata": {},
   "source": [
    "### daily baseline from TRAIN only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d477d8-f055-47b6-90b1-8d6bd7555382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_baseline(train_series, index_like):\n",
    "    tod = (index_like.hour*60 + index_like.minute)//10\n",
    "    group = (train_series.index.hour*60 + train_series.index.minute)//10\n",
    "    base = train_series.groupby(group).median()\n",
    "    return base.reindex(tod).values\n",
    "\n",
    "train_df['Baseline'] = daily_baseline(train_df['Flow[cfs]'], train_df.index)\n",
    "val_df['Baseline']   = daily_baseline(train_df['Flow[cfs]'], val_df.index)\n",
    "test_df['Baseline']  = daily_baseline(train_df['Flow[cfs]'], test_df.index)\n",
    "\n",
    "# residual target\n",
    "for d in (train_df, val_df, test_df):\n",
    "    d['resid'] = d['Flow[cfs]'] - d['Baseline']\n",
    "\n",
    "# time features\n",
    "def add_time_feats(d):\n",
    "    h = d.index.hour + d.index.minute/60.0\n",
    "    d['sin_h'] = np.sin(2*np.pi*h/24.0).astype('float32')\n",
    "    d['cos_h'] = np.cos(2*np.pi*h/24.0).astype('float32')\n",
    "    dow = d.index.dayofweek\n",
    "    d['sin_d'] = np.sin(2*np.pi*dow/7.0).astype('float32')\n",
    "    d['cos_d'] = np.cos(2*np.pi*dow/7.0).astype('float32')\n",
    "    return d\n",
    "train_df=add_time_feats(train_df); val_df=add_time_feats(val_df); test_df=add_time_feats(test_df)\n",
    "\n",
    "# previous-day residual feature\n",
    "SHIFT_24H = 24*6\n",
    "for d in (train_df, val_df, test_df):\n",
    "    d['resid_prevday'] = d['resid'].shift(SHIFT_24H)\n",
    "\n",
    "# drop first 24h in each split\n",
    "for name, d in [('train',train_df),('val',val_df),('test',test_df)]:\n",
    "    d.dropna(subset=['resid_prevday'], inplace=True)\n",
    "\n",
    "# scale residuals (train only)\n",
    "scaler = StandardScaler().fit(train_df[['resid']].values)\n",
    "for d in (train_df, val_df, test_df):\n",
    "    d['resid_z'] = scaler.transform(d[['resid']].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e1b51a-53e4-4067-8b70-14cb4488a7a4",
   "metadata": {},
   "source": [
    "### arrays & sliding windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd39988-d05a-446a-82ca-5240fb720182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_matrix(d):\n",
    "    X = d[['resid_z','resid_prevday','sin_h','cos_h','sin_d','cos_d']].astype('float32').values\n",
    "    # return baseline (cfs) and flow (cfs) in case you need them later\n",
    "    return X, d['Baseline'].values.astype('float32'), d['Flow[cfs]'].values.astype('float32')\n",
    "\n",
    "def make_windows_mv(X, lookback=L, horizon=H):\n",
    "    T=len(X); N=T - lookback - horizon + 1\n",
    "    if N<=0:\n",
    "        return np.empty((0,lookback,X.shape[1]),dtype='float32'), np.empty((0,horizon),dtype='float32')\n",
    "    s0,s1 = X.strides\n",
    "    Xw = np.lib.stride_tricks.as_strided(X, shape=(N,lookback,X.shape[1]),\n",
    "                                         strides=(s0,s0,s1)).copy()\n",
    "    # target: future residual_z (column 0)\n",
    "    y  = np.lib.stride_tricks.as_strided(X[lookback:,0], shape=(N,horizon),\n",
    "                                         strides=(s0,s0)).copy()\n",
    "    return Xw, y\n",
    "\n",
    "def future_time_feats(d, lookback=L, horizon=H):\n",
    "    feats = d[['sin_h','cos_h','sin_d','cos_d']].astype('float32').values\n",
    "    T=len(feats); N=T - lookback - horizon + 1\n",
    "    if N<=0: return np.empty((0,horizon,4),dtype='float32')\n",
    "    s0,s1 = feats.strides\n",
    "    return np.lib.stride_tricks.as_strided(feats[lookback:], shape=(N,horizon,4),\n",
    "                                           strides=(s0,s0,s1)).copy()\n",
    "\n",
    "def future_baseline(B, lookback=L, horizon=H):\n",
    "    B=B.astype('float32'); T=len(B); N=T - lookback - horizon + 1\n",
    "    if N<=0: return np.empty((0,horizon),dtype='float32')\n",
    "    s0=B.strides[0]\n",
    "    return np.lib.stride_tricks.as_strided(B[lookback:], shape=(N,horizon),\n",
    "                                           strides=(s0,s0)).copy()\n",
    "\n",
    "# build arrays\n",
    "Xtr, Btr, _ = base_matrix(train_df)\n",
    "Xva, Bva, _ = base_matrix(val_df)\n",
    "Xte, Bte, _ = base_matrix(test_df)\n",
    "\n",
    "X_train, y_train = make_windows_mv(Xtr, L, H)\n",
    "X_val,   y_val   = make_windows_mv(Xva, L, H)\n",
    "X_test,  y_test  = make_windows_mv(Xte, L, H)\n",
    "\n",
    "F_train = future_time_feats(train_df, L, H)\n",
    "F_val   = future_time_feats(val_df,   L, H)\n",
    "F_test  = future_time_feats(test_df,  L, H)\n",
    "\n",
    "BL_train = future_baseline(Btr, L, H)\n",
    "BL_val   = future_baseline(Bva, L, H)\n",
    "BL_test  = future_baseline(Bte, L, H)\n",
    "\n",
    "print(\"Shapes:\",\n",
    "      \"\\n  X_train\", X_train.shape, \"y_train\", y_train.shape, \"F_train\", F_train.shape, \"BL_train\", BL_train.shape,\n",
    "      \"\\n  X_val  \", X_val.shape,   \"y_val  \", y_val.shape,   \"F_val  \", F_val.shape,   \"BL_val  \", BL_val.shape,\n",
    "      \"\\n  X_test \", X_test.shape,  \"y_test \", y_test.shape,  \"F_test \", F_test.shape,  \"BL_test \", BL_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18d0a6d-90c3-43dc-9f45-3550f2d4e4b5",
   "metadata": {},
   "source": [
    "### Datasets / Loaders (Windows/Jupyter safe) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43360b65-d43c-449b-a155-036f550045db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletDS(Dataset):\n",
    "    def __init__(self, X, y, F, BL):\n",
    "        self.X=torch.from_numpy(X)\n",
    "        self.y=torch.from_numpy(y)\n",
    "        self.F=torch.from_numpy(F)\n",
    "        self.BL=torch.from_numpy(BL)\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self,i):\n",
    "        return self.X[i].float(), self.y[i].float(), self.F[i].float(), self.BL[i].float()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_loader = DataLoader(TripletDS(X_train,y_train,F_train,BL_train),\n",
    "                          batch_size=128, shuffle=True,  num_workers=0, pin_memory=(device.type=='cuda'))\n",
    "val_loader   = DataLoader(TripletDS(X_val,y_val,F_val,BL_val),\n",
    "                          batch_size=256, shuffle=False, num_workers=0, pin_memory=(device.type=='cuda'))\n",
    "test_loader  = DataLoader(TripletDS(X_test,y_test,F_test,BL_test),\n",
    "                          batch_size=256, shuffle=False, num_workers=0, pin_memory=(device.type=='cuda'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efac86e1-bf4d-4720-9d22-3dc3dc338c4a",
   "metadata": {},
   "source": [
    "### LSTM encoder–decoder with attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39438bd-639b-435e-80fa-d61910d36f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnSeq2Seq(nn.Module):\n",
    "    def __init__(self, input_dim, enc_h=256, dec_h=256, horizon=H):\n",
    "        super().__init__()\n",
    "        self.horizon = horizon\n",
    "        self.encoder = nn.LSTM(input_dim, enc_h, num_layers=2, batch_first=True)\n",
    "        self.Wa = nn.Linear(enc_h, dec_h, bias=False)          # Luong-style projection\n",
    "        self.dec_in = nn.Linear(1 + 4 + enc_h, dec_h)          # prev_y + 4 future time feats + context\n",
    "        self.decoder = nn.LSTM(dec_h, dec_h, num_layers=1, batch_first=True)\n",
    "        self.out = nn.Linear(dec_h, 1)\n",
    "\n",
    "    def attend(self, dec_h_t, enc_out):\n",
    "        # dec_h_t: [B, dec_h], enc_out: [B, L, enc_h]\n",
    "        proj = self.Wa(enc_out)                                # [B, L, dec_h]\n",
    "        scores = torch.einsum('bld,bd->bl', proj, dec_h_t)     # [B, L]\n",
    "        alpha = torch.softmax(scores, dim=1)\n",
    "        ctx = torch.einsum('bl,bld->bd', alpha, enc_out)       # [B, enc_h]\n",
    "        return ctx\n",
    "\n",
    "    def forward(self, x, future_feats, y_teacher=None, tf_ratio=0.5):\n",
    "        B = x.size(0)\n",
    "        enc_out, (h, c) = self.encoder(x)              # enc_out: [B, L, enc_h]\n",
    "        dec_h = h[-1]                                  # [B, enc_h]\n",
    "        dec_c = torch.zeros_like(dec_h).unsqueeze(0)   # [1, B, enc_h]\n",
    "        dec_state = (dec_h.unsqueeze(0), dec_c)\n",
    "    \n",
    "        y_prev = torch.zeros(B, 1, device=x.device)    # [B, 1]\n",
    "        outs = []\n",
    "    \n",
    "        for t in range(self.horizon):\n",
    "            # attention context\n",
    "            ctx = self.attend(dec_state[0].squeeze(0), enc_out)  # [B, enc_h]\n",
    "    \n",
    "            # ---- robust reshape to 2D before concat ----\n",
    "            feat_t = future_feats[:, t, :] if future_feats.dim() == 3 else future_feats   # [B, 4]\n",
    "            y_prev = y_prev.view(B, 1)                                                    # [B, 1]\n",
    "            feat_t = feat_t.view(B, -1)                                                   # [B, 4]\n",
    "            ctx    = ctx.view(B, -1)                                                      # [B, enc_h]\n",
    "            din    = torch.cat([y_prev, feat_t, ctx], dim=1)                              # [B, 1+4+enc_h]\n",
    "            # --------------------------------------------\n",
    "    \n",
    "            din = torch.relu(self.dec_in(din)).unsqueeze(1)  # [B, 1, dec_h]\n",
    "            dec_out, dec_state = self.decoder(din, dec_state)\n",
    "            y_t = self.out(dec_out).squeeze(1)               # [B]\n",
    "    \n",
    "            outs.append(y_t.unsqueeze(1))\n",
    "            if self.training and (y_teacher is not None) and (np.random.rand() < tf_ratio):\n",
    "                y_prev = y_teacher[:, t].unsqueeze(1)        # [B, 1]\n",
    "            else:\n",
    "                y_prev = y_t.detach().unsqueeze(1)           # [B, 1]\n",
    "    \n",
    "        return torch.cat(outs, dim=1)                         # [B, H]\n",
    "\n",
    "input_dim = X_train.shape[2]\n",
    "model = AttnSeq2Seq(input_dim=input_dim, enc_h=256, dec_h=256, horizon=H).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b7abef-5779-4671-a2ea-35c90a71fb6d",
   "metadata": {},
   "source": [
    "### Training (AMP-compatible across torch versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669c4223-c81f-4f63-ab68-8f70e823dedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== 6) Training (fixed AMP + output shape) =====================\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# --- choose correct AMP API ---\n",
    "if hasattr(torch, \"amp\") and hasattr(torch.amp, \"GradScaler\"):\n",
    "    from torch import amp\n",
    "    GradScaler = amp.GradScaler\n",
    "    autocast   = amp.autocast\n",
    "    autocast_kwargs = {\"device_type\": \"cuda\"} if torch.cuda.is_available() else {}\n",
    "else:\n",
    "    from torch.cuda.amp import GradScaler, autocast\n",
    "    autocast_kwargs = {}\n",
    "\n",
    "opt   = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
    "sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min', patience=4, factor=0.5)\n",
    "crit  = nn.MSELoss()\n",
    "scaler_amp = GradScaler(enabled=torch.cuda.is_available())\n",
    "\n",
    "best = np.inf\n",
    "patience = 10\n",
    "pat = 0\n",
    "best_state = None\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "# --- validation helper ---\n",
    "def eval_loader(dl):\n",
    "    model.eval()\n",
    "    losses=[]\n",
    "    with torch.no_grad():\n",
    "        for xb,yb,Fb,BLb in dl:\n",
    "            xb,yb,Fb = xb.to(device), yb.to(device), Fb.to(device)\n",
    "            yhat = model(xb, Fb, None, 0.0)\n",
    "            if yhat.ndim == 3 and yhat.shape[-1] == 1:\n",
    "                yhat = yhat.squeeze(-1)  # <-- FIX\n",
    "            loss = crit(yhat, yb)\n",
    "            losses.append(loss.item())\n",
    "    return float(np.mean(losses)) if len(losses)>0 else np.inf\n",
    "\n",
    "\n",
    "# --- main train loop ---\n",
    "for ep in range(1, 120+1):\n",
    "    model.train()\n",
    "    tr=[]\n",
    "    for xb,yb,Fb,BLb in train_loader:\n",
    "        xb,yb,Fb = xb.to(device), yb.to(device), Fb.to(device)\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "\n",
    "        with autocast(**autocast_kwargs):\n",
    "            yhat = model(xb, Fb, y_teacher=yb, tf_ratio=0.5)\n",
    "            if yhat.ndim == 3 and yhat.shape[-1] == 1:\n",
    "                yhat = yhat.squeeze(-1)  # <-- FIX\n",
    "            loss = crit(yhat, yb)\n",
    "\n",
    "        scaler_amp.scale(loss).backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler_amp.step(opt)\n",
    "        scaler_amp.update()\n",
    "        tr.append(loss.item())\n",
    "\n",
    "    # validation + scheduler\n",
    "    val_loss = eval_loader(val_loader)\n",
    "    sched.step(val_loss)\n",
    "\n",
    "    train_losses.append(np.mean(tr))\n",
    "    val_losses.append(val_loss)\n",
    "    print(f\"Epoch {ep:03d} | train {np.mean(tr):.6f} | val {val_loss:.6f}\")\n",
    "\n",
    "    if val_loss < best - 1e-6:\n",
    "        best = val_loss\n",
    "        best_state = {k:v.cpu().clone() for k,v in model.state_dict().items()}\n",
    "        pat = 0\n",
    "    else:\n",
    "        pat += 1\n",
    "        if pat >= patience:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e07a39-6840-4afe-9385-27768d004b72",
   "metadata": {},
   "source": [
    "### evaluate in cfs (inverse residuals + add baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c16f365-eb15-486d-b3f5-03aec8359381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== Evaluation (robust shapes) =====================\n",
    "import numpy as np\n",
    "\n",
    "def _to_2d(a):\n",
    "    # Accept [N,H] or [N,H,1] and return [N,H]\n",
    "    return a.squeeze(-1) if (a.ndim == 3 and a.shape[-1] == 1) else a\n",
    "\n",
    "def residz_to_flow(y_residz, BL):\n",
    "    # y_residz, BL expected [N,H] (2-D)\n",
    "    y_residz = _to_2d(y_residz)\n",
    "    BL       = _to_2d(BL)\n",
    "    resid = scaler.inverse_transform(y_residz.reshape(-1, 1)).reshape(y_residz.shape)\n",
    "    return resid + BL\n",
    "\n",
    "model.eval(); preds=[]; truth=[]; BLs=[]\n",
    "with torch.no_grad():\n",
    "    for xb, yb, Fb, BLb in test_loader:\n",
    "        xb, Fb = xb.to(device), Fb.to(device)\n",
    "        yhat = model(xb, Fb, None, 0.0).cpu().numpy()  # could be [B,H] or [B,H,1]\n",
    "        preds.append(yhat)\n",
    "        truth.append(yb.numpy())                        # [B,H]\n",
    "        BLs.append(BLb.numpy())                         # [B,H]\n",
    "\n",
    "y_pred_s = _to_2d(np.vstack(preds))  # [N,H]\n",
    "y_true_s = _to_2d(np.vstack(truth))  # [N,H]\n",
    "BL_arr   = _to_2d(np.vstack(BLs))    # [N,H]\n",
    "\n",
    "y_pred = residz_to_flow(y_pred_s, BL_arr)  # cfs, [N,H]\n",
    "y_true = residz_to_flow(y_true_s, BL_arr)  # cfs, [N,H]\n",
    "\n",
    "def metrics(y_true, y_pred):\n",
    "    mae  = np.mean(np.abs(y_true - y_pred), axis=0)                 # per-horizon\n",
    "    rmse = np.sqrt(np.mean((y_true - y_pred)**2, axis=0))           # per-horizon\n",
    "    mae_all  = float(np.mean(np.abs(y_true - y_pred)))              # overall\n",
    "    rmse_all = float(np.sqrt(np.mean((y_true - y_pred)**2)))        # overall\n",
    "    return mae, rmse, mae_all, rmse_all\n",
    "\n",
    "mae_h, rmse_h, mae_all, rmse_all = metrics(y_true, y_pred)\n",
    "\n",
    "print(\"\\n=== Test metrics (cfs) ===\")\n",
    "for i in range(y_pred.shape[1]):\n",
    "    print(f\"+{(i+1)*10:>3} min: MAE={mae_h[i]:.4f} | RMSE={rmse_h[i]:.4f}\")\n",
    "print(f\"Overall MAE: {mae_all:.4f} cfs | Overall RMSE: {rmse_all:.4f} cfs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33ba8c3-223f-469f-a56a-5fddaf7e5436",
   "metadata": {},
   "source": [
    "### plot a test sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf12822-9461-4742-b88e-eb496b3e59e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "test_series = test_df['Flow[cfs]']  # keep your original column name\n",
    "\n",
    "def plot_test_sample(k=0):\n",
    "    idx = test_series.index\n",
    "    Nw = len(idx) - L - H + 1\n",
    "    if Nw <= 0:\n",
    "        raise ValueError(\"No test windows. Check L/H and split sizes.\")\n",
    "    k = max(0, min(k, Nw-1))\n",
    "    hist = slice(k, k+L); fut = slice(k+L, k+L+H)\n",
    "    ht, ft = idx[hist], idx[fut]\n",
    "    hist_vals = test_series.iloc[hist].values\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.plot(ht, hist_vals, label=\"History (24h)\", lw=1.5)\n",
    "    plt.plot(ft, y_true[k], label=\"Observed (6h)\", lw=2)\n",
    "    plt.plot(ft, y_pred[k], label=\"Predicted (6h)\", lw=2, ls=\"--\")\n",
    "    t_cut = ht[-1]\n",
    "    ymax = max(hist_vals.max(), y_true[k].max()) * 1.02\n",
    "    plt.axvline(t_cut, ls=':', lw=1)\n",
    "    plt.text(t_cut, ymax, \"forecast start\", rotation=90, va=\"bottom\")\n",
    "    plt.xlabel(\"Time\"); plt.ylabel(\"Flow (cfs)\")\n",
    "    plt.title(f\"Test sample #{k} — Feature-enhanced LSTM\")\n",
    "    plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "# Example:\n",
    "plot_test_sample(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e45e578-a296-42c4-8c02-f6a143216b64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dffde2-871b-4567-971f-3fbdde5a332c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_test_sample(k=0):\n",
    "    idx = test_series.index\n",
    "    Nw = len(idx) - L - H + 1\n",
    "    k = max(0, min(k, Nw-1))\n",
    "    hist = slice(k, k+L)\n",
    "    fut  = slice(k+L, k+L+H)\n",
    "    ht, ft = idx[hist], idx[fut]\n",
    "    hist_vals = test_series.iloc[hist].values\n",
    "\n",
    "    # combine for a smooth line\n",
    "    combined_time = np.concatenate([ht[-1:], ft])\n",
    "    combined_obs  = np.concatenate([hist_vals[-1:], y_true[k]])\n",
    "\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.plot(ht, hist_vals, label=\"History (24h)\", lw=1.5)\n",
    "    plt.plot(combined_time, combined_obs, label=\"Observed (6h)\", lw=2)\n",
    "    plt.plot(ft, y_pred[k], label=\"Predicted (6h)\", lw=2, ls=\"--\")\n",
    "\n",
    "    t_cut = ht[-1]\n",
    "    ymax = max(hist_vals.max(), y_true[k].max()) * 1.02\n",
    "    plt.axvline(t_cut, ls=':', lw=1)\n",
    "    plt.text(t_cut, ymax, \"forecast start\", rotation=90, va=\"bottom\")\n",
    "    plt.xlabel(\"Time\"); plt.ylabel(\"Flow (cfs)\")\n",
    "    plt.title(f\"Test sample #{k} — Feature-enhanced LSTM (1-hour horizon)\")\n",
    "    plt.legend(); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbfbb70-c196-4506-9739-dee1b05be7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_test_sample(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19f2cbb-12ca-4e94-b129-5d8f25c75296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f656df-2f35-4972-8019-a9b5e65c2910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_series = test_df['Flow[cfs]']  # keep your original column name\n",
    "\n",
    "def plot_test_sample(k=0):\n",
    "    idx = test_series.index\n",
    "    Nw = len(idx) - L - H + 1\n",
    "    if Nw <= 0:\n",
    "        raise ValueError(\"No test windows. Check L/H and split sizes.\")\n",
    "    k = max(0, min(k, Nw-1))\n",
    "\n",
    "    hist = slice(k, k+L)\n",
    "    fut  = slice(k+L, k+L+H)\n",
    "    ht, ft = idx[hist], idx[fut]\n",
    "    hist_vals = test_series.iloc[hist].values\n",
    "\n",
    "    # ---- build continuous curves ----\n",
    "    obs_time = np.concatenate([ht[-1:], ft])          # join last history point\n",
    "    obs_vals = np.concatenate([hist_vals[-1:], y_true[k]])\n",
    "    pred_time = np.concatenate([ht[-1:], ft])\n",
    "    pred_vals = np.concatenate([hist_vals[-1:], y_pred[k]])\n",
    "\n",
    "    # ---- plot ----\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(ht, hist_vals, label=\"History (24h)\", lw=1.5, color='tab:blue')\n",
    "    plt.plot(obs_time, obs_vals, label=\"Observed (1h)\", lw=2, color='tab:orange')\n",
    "    plt.plot(pred_time, pred_vals, label=\"Predicted (1h)\", lw=2, ls=\"--\", color='tab:green')\n",
    "\n",
    "    t_cut = ht[-1]\n",
    "    ymax = max(hist_vals.max(), y_true[k].max()) * 1.02\n",
    "    plt.axvline(t_cut, ls=':', lw=1)\n",
    "    plt.text(t_cut, ymax, \"forecast start\", rotation=90, va=\"bottom\")\n",
    "    plt.xlabel(\"Time\"); plt.ylabel(\"Flow (cfs)\")\n",
    "    plt.title(f\"Test sample #{k} — Feature-enhanced LSTM (1-hour horizon)\")\n",
    "    plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "# Example:\n",
    "plot_test_sample(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e9a8b5-7df9-45ea-88fb-5cfe35aa4aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78c193a0-02c6-47cc-a742-093a4591449c",
   "metadata": {},
   "source": [
    "## Attempt 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f28b1f-d611-4934-b96e-181615529916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, random\n",
    "from math import sqrt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler # <-- ADD StandardScaler\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c7811d-b853-437a-93a8-0e3efc114ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "H, L = 18, 144   # 6h horizon, 24h lookback (10-min steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f94c024-62db-4ccb-b6f2-e3958cb65d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = flow_10min.copy().sort_index().asfreq('10min')\n",
    "assert 'Flow[cfs]' in df.columns, \"Expected a column named 'Flow[cfs]'\"\n",
    "df['Flow[cfs]'] = df['Flow[cfs]'].interpolate(limit_direction='both')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f6f904-33c3-49e2-8d49-0630eb21b9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=len(df); n_tr=int(0.70*N); n_va=int(0.15*N)\n",
    "train_df=df.iloc[:n_tr].copy()\n",
    "val_df  =df.iloc[n_tr:n_tr+n_va].copy()\n",
    "test_df =df.iloc[n_tr+n_va:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e771d9-4eab-4b62-8534-705e43d71052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_baseline(train_series, index_like):\n",
    "    tod = (index_like.hour*60 + index_like.minute)//10\n",
    "    group = (train_series.index.hour*60 + train_series.index.minute)//10\n",
    "    base = train_series.groupby(group).median()\n",
    "    return base.reindex(tod).values\n",
    "\n",
    "train_df['Baseline'] = daily_baseline(train_df['Flow[cfs]'], train_df.index)\n",
    "val_df['Baseline']   = daily_baseline(train_df['Flow[cfs]'], val_df.index)\n",
    "test_df['Baseline']  = daily_baseline(train_df['Flow[cfs]'], test_df.index)\n",
    "\n",
    "\n",
    "################\n",
    "# 1. Calculate the 'base' object as a Pandas Series\n",
    "# (This is the logic from inside your function, but we stop before .values)\n",
    "group = (train_df.index.hour * 60 + train_df.index.minute) // 10\n",
    "base_series = train_df['Flow[cfs]'].groupby(group).median()\n",
    "\n",
    "# 2. Save the Pandas Series to a CSV file\n",
    "base_series.to_csv(\"daily_baseline_v2.csv\", header=False)\n",
    "print(\"Successfully saved daily_baseline.csv\")\n",
    "####################\n",
    "\n",
    "# residual target\n",
    "for d in (train_df, val_df, test_df):\n",
    "    d['resid'] = d['Flow[cfs]'] - d['Baseline']\n",
    "\n",
    "# time features\n",
    "def add_time_feats(d):\n",
    "    h = d.index.hour + d.index.minute/60.0\n",
    "    d['sin_h'] = np.sin(2*np.pi*h/24.0).astype('float32')\n",
    "    d['cos_h'] = np.cos(2*np.pi*h/24.0).astype('float32')\n",
    "    dow = d.index.dayofweek\n",
    "    d['sin_d'] = np.sin(2*np.pi*dow/7.0).astype('float32')\n",
    "    d['cos_d'] = np.cos(2*np.pi*dow/7.0).astype('float32')\n",
    "    return d\n",
    "train_df=add_time_feats(train_df); val_df=add_time_feats(val_df); test_df=add_time_feats(test_df)\n",
    "\n",
    "# previous-day residual feature\n",
    "SHIFT_24H = 24*6\n",
    "for d in (train_df, val_df, test_df):\n",
    "    d['resid_prevday'] = d['resid'].shift(SHIFT_24H)\n",
    "\n",
    "# drop first 24h in each split\n",
    "for name, d in [('train',train_df),('val',val_df),('test',test_df)]:\n",
    "    d.dropna(subset=['resid_prevday'], inplace=True)\n",
    "\n",
    "# scale residuals (train only)\n",
    "scaler = StandardScaler().fit(train_df[['resid']].values)\n",
    "for d in (train_df, val_df, test_df):\n",
    "    d['resid_z'] = scaler.transform(d[['resid']].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e549018-76bf-4c1c-981a-47b455525333",
   "metadata": {},
   "source": [
    "### Add residual derivative + (re)scale residuals & derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355a1fc5-9bee-4b29-be99-adcef46fd44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "for d in (train_df, val_df, test_df):\n",
    "    d['resid_diff'] = d['resid'].diff().fillna(0.0)\n",
    "\n",
    "scaler = StandardScaler().fit(train_df[['resid','resid_diff']].values)\n",
    "\n",
    "# --- ADD THIS LINE TO SAVE IT ---\n",
    "# Use the *original* filename to overwrite the old file\n",
    "joblib.dump(scaler, \"flow_data_scaler.joblib\")\n",
    "print(\"✅ Successfully saved new flow_data_scaler.joblib\")\n",
    "# ---\n",
    "\n",
    "\n",
    "for d in (train_df, val_df, test_df):\n",
    "    d[['resid_z','resid_diff_z']] = scaler.transform(d[['resid','resid_diff']].values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d0e1a4-b445-49e2-bd0e-44a90c03e1db",
   "metadata": {},
   "source": [
    "### Arrays & sliding windows (H=18, L=144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a97ae6-5d7a-4b70-95ff-2a626f1b1a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "H, L = 18, 144   # 6-hour horizon, 24h lookback\n",
    "\n",
    "def base_matrix(d):\n",
    "    # NEW: include resid_diff_z (momentum)\n",
    "    X = d[['resid_z','resid_diff_z','resid_prevday','sin_h','cos_h','sin_d','cos_d']].astype('float32').values\n",
    "    return X, d['Baseline'].values.astype('float32'), d['Flow[cfs]'].values.astype('float32')\n",
    "\n",
    "def make_windows_mv(X, lookback=L, horizon=H):\n",
    "    T=len(X); N=T - lookback - horizon + 1\n",
    "    if N<=0: return np.empty((0,lookback,X.shape[1]),dtype='float32'), np.empty((0,horizon),dtype='float32')\n",
    "    s0,s1 = X.strides\n",
    "    Xw = np.lib.stride_tricks.as_strided(X, shape=(N,lookback,X.shape[1]), strides=(s0,s0,s1)).copy()\n",
    "    y  = np.lib.stride_tricks.as_strided(X[lookback:,0], shape=(N,horizon), strides=(s0,s0)).copy()\n",
    "    return Xw, y\n",
    "\n",
    "def future_time_feats(d, lookback=L, horizon=H):\n",
    "    feats = d[['sin_h','cos_h','sin_d','cos_d']].astype('float32').values\n",
    "    T=len(feats); N=T - lookback - horizon + 1\n",
    "    if N<=0: return np.empty((0,horizon,4),dtype='float32')\n",
    "    s0,s1 = feats.strides\n",
    "    return np.lib.stride_tricks.as_strided(feats[lookback:], shape=(N,horizon,4), strides=(s0,s0,s1)).copy()\n",
    "\n",
    "def future_baseline(B, lookback=L, horizon=H):\n",
    "    B=B.astype('float32'); T=len(B); N=T - lookback - horizon + 1\n",
    "    if N<=0: return np.empty((0,horizon),dtype='float32')\n",
    "    s0=B.strides[0]\n",
    "    return np.lib.stride_tricks.as_strided(B[lookback:], shape=(N,horizon), strides=(s0,s0)).copy()\n",
    "\n",
    "Xtr,Btr,_ = base_matrix(train_df); Xva,Bva,_ = base_matrix(val_df); Xte,Bte,_ = base_matrix(test_df)\n",
    "X_train,y_train = make_windows_mv(Xtr,L,H); X_val,y_val = make_windows_mv(Xva,L,H); X_test,y_test = make_windows_mv(Xte,L,H)\n",
    "F_train = future_time_feats(train_df,L,H); F_val = future_time_feats(val_df,L,H); F_test = future_time_feats(test_df,L,H)\n",
    "BL_train = future_baseline(Btr,L,H); BL_val = future_baseline(Bva,L,H); BL_test = future_baseline(Bte,L,H)\n",
    "\n",
    "class TripletDS(Dataset):\n",
    "    def __init__(self,X,y,F,BL): self.X=torch.from_numpy(X); self.y=torch.from_numpy(y); self.F=torch.from_numpy(F); self.BL=torch.from_numpy(BL)\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self,i): return self.X[i].float(), self.y[i].float(), self.F[i].float(), self.BL[i].float()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_loader = DataLoader(TripletDS(X_train,y_train,F_train,BL_train), batch_size=128, shuffle=True,  num_workers=0, pin_memory=(device.type=='cuda'))\n",
    "val_loader   = DataLoader(TripletDS(X_val,y_val,F_val,BL_val),       batch_size=256, shuffle=False, num_workers=0, pin_memory=(device.type=='cuda'))\n",
    "test_loader  = DataLoader(TripletDS(X_test,y_test,F_test,BL_test),   batch_size=256, shuffle=False, num_workers=0, pin_memory=(device.type=='cuda'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f4516a-ad9f-49d1-aab7-8e1a9b0c2121",
   "metadata": {},
   "source": [
    "### Model: Attn Seq2Seq with bigger hidden & dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb96a002-b39f-4084-a6d9-0989e136951d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnSeq2Seq(nn.Module):\n",
    "    def __init__(self, input_dim, enc_h=384, dec_h=384, horizon=H):\n",
    "        super().__init__()\n",
    "        self.horizon = horizon\n",
    "        self.encoder = nn.LSTM(input_dim, enc_h, num_layers=2, batch_first=True, dropout=0.1)\n",
    "        self.Wa = nn.Linear(enc_h, dec_h, bias=False)\n",
    "        self.dec_in = nn.Linear(1 + 4 + enc_h, dec_h)   # prev_y + 4 future time feats + context\n",
    "        self.decoder = nn.LSTM(dec_h, dec_h, num_layers=1, batch_first=True)\n",
    "        self.out = nn.Linear(dec_h, 1)\n",
    "\n",
    "    def attend(self, dec_h_t, enc_out):\n",
    "        # enc_out: [B, L, enc_h], dec_h_t: [B, dec_h]\n",
    "        proj = self.Wa(enc_out)                                # [B, L, dec_h]\n",
    "        scores = torch.einsum('bld,bd->bl', proj, dec_h_t)     # [B, L]\n",
    "        alpha = torch.softmax(scores, dim=1)                   # [B, L]\n",
    "        ctx = torch.einsum('bl,bld->bd', alpha, enc_out)       # [B, enc_h]\n",
    "        return ctx\n",
    "\n",
    "    def forward(self, x, future_feats, y_teacher=None, tf_ratio=0.5):\n",
    "        B = x.size(0)\n",
    "        enc_out, (h, c) = self.encoder(x)                      # enc_out: [B, L, enc_h]\n",
    "        dec_h = h[-1]                                          # [B, enc_h]\n",
    "        dec_c = torch.zeros_like(dec_h).unsqueeze(0)           # [1, B, enc_h]\n",
    "        dec_state = (dec_h.unsqueeze(0), dec_c)\n",
    "\n",
    "        y_prev = torch.zeros(B, 1, device=x.device)            # [B, 1]\n",
    "        outs = []\n",
    "\n",
    "        for t in range(self.horizon):\n",
    "            ctx = self.attend(dec_state[0].squeeze(0), enc_out)    # [B, enc_h]\n",
    "\n",
    "            # ---- force everything to 2D before concat ----\n",
    "            feat_t = future_feats[:, t]                           # expected [B, 4] but guard shapes:\n",
    "            if feat_t.dim() == 3:  # e.g., [B,1,4]\n",
    "                feat_t = feat_t.squeeze(1)\n",
    "            feat_t = feat_t.reshape(B, -1)                        # [B, 4]\n",
    "            y_prev = y_prev.reshape(B, 1)                         # [B, 1]\n",
    "            ctx    = ctx.reshape(B, -1)                           # [B, enc_h]\n",
    "\n",
    "            din = torch.cat([y_prev, feat_t, ctx], dim=1)         # [B, 1+4+enc_h]\n",
    "            din = torch.relu(self.dec_in(din)).unsqueeze(1)       # [B, 1, dec_h]\n",
    "            dec_out, dec_state = self.decoder(din, dec_state)     # [B, 1, dec_h]\n",
    "            y_t = self.out(dec_out).squeeze(1)                    # [B]\n",
    "\n",
    "            outs.append(y_t.unsqueeze(1))                         # [B, 1]\n",
    "            # teacher forcing\n",
    "            if self.training and (y_teacher is not None) and (np.random.rand() < tf_ratio):\n",
    "                y_prev = y_teacher[:, t].unsqueeze(1)             # [B, 1]\n",
    "            else:\n",
    "                y_prev = y_t.detach().unsqueeze(1)                # [B, 1]\n",
    "\n",
    "        return torch.cat(outs, dim=1)                             # [B, H]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d1981f-fd18-4240-9f71-b23b8f74b77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AttnSeq2Seq(input_dim=X_train.shape[2], enc_h=384, dec_h=384, horizon=H).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fddb33d-4bf6-4555-bd07-2d933ddf1a16",
   "metadata": {},
   "source": [
    "### Training (AMP-safe; LR=1e-3; output-shape fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95b5293-2295-4a46-919f-51d4ab859aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= D) Training (AMP-safe; LR=1e-3; output-shape fix) =========\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# AMP compatibility for your torch version\n",
    "if hasattr(torch, \"amp\") and hasattr(torch.amp, \"GradScaler\"):\n",
    "    from torch import amp\n",
    "    GradScaler = amp.GradScaler; autocast = amp.autocast\n",
    "    autocast_kwargs = {\"device_type\":\"cuda\"} if torch.cuda.is_available() else {}\n",
    "else:\n",
    "    from torch.cuda.amp import GradScaler, autocast\n",
    "    autocast_kwargs = {}\n",
    "\n",
    "opt   = torch.optim.Adam(model.parameters(), lr=1e-3)  # LOWER LR\n",
    "sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min', patience=4, factor=0.5)\n",
    "crit  = nn.MSELoss()\n",
    "scaler_amp = GradScaler(enabled=torch.cuda.is_available())\n",
    "\n",
    "best = np.inf; patience = 15; pat = 0; best_state = None\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "def eval_loader(dl):\n",
    "    model.eval(); losses=[]\n",
    "    with torch.no_grad():\n",
    "        for xb,yb,Fb,BLb in dl:\n",
    "            xb,yb,Fb = xb.to(device), yb.to(device), Fb.to(device)\n",
    "            yhat = model(xb, Fb, None, 0.0)\n",
    "            if yhat.ndim == 3 and yhat.shape[-1] == 1:\n",
    "                yhat = yhat.squeeze(-1)\n",
    "            losses.append(crit(yhat, yb).item())\n",
    "    return float(np.mean(losses)) if len(losses)>0 else np.inf\n",
    "\n",
    "for ep in range(1, 150+1):\n",
    "    model.train(); tr=[]\n",
    "    for xb,yb,Fb,BLb in train_loader:\n",
    "        xb,yb,Fb = xb.to(device), yb.to(device), Fb.to(device)\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        with autocast(**autocast_kwargs):\n",
    "            yhat = model(xb, Fb, y_teacher=yb, tf_ratio=0.5)\n",
    "            if yhat.ndim == 3 and yhat.shape[-1] == 1:\n",
    "                yhat = yhat.squeeze(-1)    # make [B,H]\n",
    "            loss = crit(yhat, yb)\n",
    "        scaler_amp.scale(loss).backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler_amp.step(opt); scaler_amp.update()\n",
    "        tr.append(loss.item())\n",
    "    v = eval_loader(val_loader); sched.step(v)\n",
    "    train_losses.append(np.mean(tr)); val_losses.append(v)\n",
    "    print(f\"Epoch {ep:03d} | train {np.mean(tr):.6f} | val {v:.6f}\")\n",
    "    if v < best - 1e-6:\n",
    "        best = v; best_state = {k:v.cpu().clone() for k,v in model.state_dict().items()}; pat = 0\n",
    "    else:\n",
    "        pat += 1\n",
    "        if pat >= patience:\n",
    "            print(\"Early stopping\"); break\n",
    "\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state); model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d077df4d-bcea-4553-ab41-55a6a4c5a2e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d43a492-67af-442d-b77e-4c7328c14863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Path where you want to save it\n",
    "save_path = \"lstm_flow_model.pth\"\n",
    "\n",
    "# Recommended: save both weights + metadata\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'input_dim': X_train.shape[2],\n",
    "    'enc_h': 384,\n",
    "    'dec_h': 384,\n",
    "    'horizon': H,\n",
    "    'scaler_mean': scaler.mean_,       # save scaling params too\n",
    "    'scaler_scale': scaler.scale_,\n",
    "    'L': L\n",
    "}, save_path)\n",
    "\n",
    "print(f\"✅ Model saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6efaeb-cdb1-46f1-8dee-c4803561b70f",
   "metadata": {},
   "source": [
    "### Evaluation & plotting (unchanged, robust to shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cd44a5-1780-480d-97db-af145be235b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= E) Evaluation & plotting (robust shapes; correct inverse for 2-col scaler) =========\n",
    "import numpy as np\n",
    "\n",
    "def _to_2d(a):  # accept [N,H] or [N,H,1] -> [N,H]\n",
    "    return a.squeeze(-1) if (a.ndim == 3 and a.shape[-1] == 1) else a\n",
    "\n",
    "def residz_to_flow(y_residz, BL):\n",
    "    y_residz = _to_2d(y_residz)   # [N,H]\n",
    "    BL       = _to_2d(BL)         # [N,H]\n",
    "    # scaler was fit on ['resid','resid_diff'] -> use only the first feature's stats\n",
    "    resid = y_residz * scaler.scale_[0] + scaler.mean_[0]   # [N,H]\n",
    "    return resid + BL                                       # flow (cfs), [N,H]\n",
    "\n",
    "model.eval(); preds=[]; truth=[]; BLs=[]\n",
    "with torch.no_grad():\n",
    "    for xb,yb,Fb,BLb in test_loader:\n",
    "        xb, Fb = xb.to(device), Fb.to(device)\n",
    "        yhat = model(xb, Fb, None, 0.0).cpu().numpy()  # [B,H] or [B,H,1]\n",
    "        preds.append(yhat)\n",
    "        truth.append(yb.numpy())\n",
    "        BLs.append(BLb.numpy())\n",
    "\n",
    "y_pred_s = _to_2d(np.vstack(preds))   # [N,H]\n",
    "y_true_s = _to_2d(np.vstack(truth))   # [N,H]\n",
    "BL_arr   = _to_2d(np.vstack(BLs))     # [N,H]\n",
    "\n",
    "y_pred = residz_to_flow(y_pred_s, BL_arr)  # cfs\n",
    "y_true = residz_to_flow(y_true_s, BL_arr)  # cfs\n",
    "\n",
    "def metrics(y_true, y_pred):\n",
    "    mae  = np.mean(np.abs(y_true - y_pred), axis=0)\n",
    "    rmse = np.sqrt(np.mean((y_true - y_pred)**2, axis=0))\n",
    "    mae_all  = float(np.mean(np.abs(y_true - y_pred)))\n",
    "    rmse_all = float(np.sqrt(np.mean((y_true - y_pred)**2)))\n",
    "    return mae, rmse, mae_all, rmse_all\n",
    "\n",
    "mae_h, rmse_h, mae_all, rmse_all = metrics(y_true, y_pred)\n",
    "print(\"\\n=== Test metrics (cfs) ===\")\n",
    "for i in range(H):\n",
    "    print(f\"+{(i+1)*10:>3} min: MAE={mae_h[i]:.4f} | RMSE={rmse_h[i]:.4f}\")\n",
    "print(f\"Overall MAE: {mae_all:.4f} cfs | Overall RMSE: {rmse_all:.4f} cfs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35254e23-4147-4a46-9210-d322ff884448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# continuous plotting (option 3)\n",
    "import matplotlib.pyplot as plt\n",
    "test_series = test_df['Flow[cfs]']\n",
    "def plot_test_sample(k=0):\n",
    "    idx = test_series.index; Nw = len(idx) - L - H + 1; k = max(0, min(k, Nw-1))\n",
    "    hist = slice(k, k+L); fut = slice(k+L, k+L+H)\n",
    "    ht, ft = idx[hist], idx[fut]; hist_vals = test_series.iloc[hist].values\n",
    "    obs_time  = np.concatenate([ht[-1:], ft]); obs_vals  = np.concatenate([hist_vals[-1:], y_true[k]])\n",
    "    pred_time = np.concatenate([ht[-1:], ft]); pred_vals = np.concatenate([hist_vals[-1:], y_pred[k]])\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.plot(ht, hist_vals, label=\"History (24h)\", lw=1.5)\n",
    "    plt.plot(obs_time,  obs_vals,  label=\"Observed (1h)\", lw=2)\n",
    "    plt.plot(pred_time, pred_vals, label=\"Predicted (1h)\", lw=2, ls=\"--\")\n",
    "    t_cut = ht[-1]; ymax = max(hist_vals.max(), y_true[k].max()) * 1.02\n",
    "    plt.axvline(t_cut, ls=':', lw=1); plt.text(t_cut, ymax, \"forecast start\", rotation=90, va=\"bottom\")\n",
    "    plt.xlabel(\"Time\"); plt.ylabel(\"Flow (cfs)\"); plt.title(f\"Test sample #{k} — Feature-enhanced LSTM (A+B)\")\n",
    "    plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "# Example:\n",
    "plot_test_sample(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131880ed-4967-433d-89e1-b6969a9cf18c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
